{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer_sizes, act_fun, out_act_fun_is_linear = True):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.n_layers = len(layer_sizes)\n",
    "        self.set_act_fun(act_fun)\n",
    "        self.set_out_act_fun(out_act_fun_is_linear)\n",
    "        \n",
    "        self.weights = [None] * (self.n_layers - 1)\n",
    "        self.biases = [None] * (self.n_layers - 1)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for i in range(self.n_layers - 1):\n",
    "            self.weights[i] = np.random.rand(self.layer_sizes[i], self.layer_sizes[i + 1])\n",
    "            self.biases[i] = np.random.rand(self.layer_sizes[i + 1], 1)        \n",
    "\n",
    "    def _forward(self, X, return_activations = False):\n",
    "        X = np.atleast_2d(X)\n",
    "        Y = np.atleast_2d([])\n",
    "        A = []\n",
    "        for i in range(X.shape[0]):\n",
    "            Y_temp = np.atleast_2d(X[i]) #if len(X.shape) > 1 else X\n",
    "            for j in range(len(self.weights) - 1):\n",
    "                A.append(self.weights[j].T.dot(Y_temp) + self.biases[j])\n",
    "                Y_temp = self.act_fun(A[-1])\n",
    "            A.append(self.weights[-1].T.dot(Y_temp) + self.biases[-1])\n",
    "            Y_temp = self.out_act_fun(A[-1])\n",
    "            Y = np.append(Y, Y_temp)\n",
    "        return (Y, A) if return_activations else Y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._forward(X)\n",
    "    \n",
    "    def _backward(self, x, y):\n",
    "        y = np.atleast_2d(y)\n",
    "        x = np.atleast_2d(x)\n",
    "        y_pred, A = self._forward(x, return_activations = True)\n",
    "        error = y_pred - y\n",
    "        D_weights = []\n",
    "        D_biases = []\n",
    "        D = []\n",
    "        for i in range(len(self.weights) - 1, -1, -1):\n",
    "            if i == len(self.weights) - 1:\n",
    "                D.insert(0, error * self.out_act_fun_prime(A[-1]))\n",
    "            else:\n",
    "                D.insert(0, np.dot(self.weights[i + 1], D[0]) * self.act_fun_prime(A[i]))\n",
    "            if i == 0:\n",
    "                D_weights.insert(0, np.outer(x, D[0]))\n",
    "            else:\n",
    "                D_weights.insert(0, np.outer(self.act_fun(A[i - 1]), D[0]))\n",
    "            D_biases.insert(0, D[0])\n",
    "        return D_weights, D_biases\n",
    "    \n",
    "    def fit_SGD(self, X, Y, first_lr = 0.01, lr_decay_rate=0.01, epochs = 100, n_epochs_displayed = 100):\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        losses = []\n",
    "        weights_over_epochs = [copy.deepcopy(self.weights)]\n",
    "        biases_over_epochs = [copy.deepcopy(self.biases)]\n",
    "        for epoch in range(epochs):\n",
    "            permutaion = np.random.permutation(X.shape[0])\n",
    "            for i in permutaion:\n",
    "                D_weights, D_biases = self._backward(X[i], Y[i])\n",
    "                learning_rate = first_lr / (1 + epoch * lr_decay_rate)\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= learning_rate * D_weights[j]\n",
    "                    self.biases[j] -= learning_rate * D_biases[j]\n",
    "            losses.append(self.mse(self.predict(X), Y))\n",
    "            weights_over_epochs.append(copy.deepcopy(self.weights))\n",
    "            biases_over_epochs.append(copy.deepcopy(self.biases))\n",
    "            if epoch == 0 or (epoch + 1) % n_epochs_displayed == 0:\n",
    "                print(f'Epoch {epoch + 1}: loss_fun={losses[-1]}')\n",
    "        return losses, weights_over_epochs, biases_over_epochs\n",
    "    \n",
    "    def fit_batch(self, X, Y, first_lr = 0.01, lr_decay_rate=0.01, epochs = 100, n_epochs_displayed = 100):\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        losses = []\n",
    "        weights_over_epochs = [self.weights]\n",
    "        biases_over_epochs = [self.biases]\n",
    "        for epoch in range(epochs):\n",
    "            permutaion = np.random.permutation(X.shape[0])\n",
    "            D_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "            D_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "            for i in permutaion:\n",
    "                D_weights_temp, D_biases_temp = self._backward(X[i], Y[i])\n",
    "                for j in range(len(self.weights)):\n",
    "                    D_weights[j] += D_weights_temp[j]\n",
    "                    D_biases[j] += D_biases_temp[j]\n",
    "            learning_rate = first_lr / (1 + epoch * lr_decay_rate)\n",
    "            for j in range(len(self.weights)):\n",
    "                self.weights[j] -= learning_rate * D_weights[j] / X.shape[0]\n",
    "                self.biases[j] -= learning_rate * D_biases[j] / X.shape[0]\n",
    "            losses.append(self.mse(self.predict(X), Y))\n",
    "            weights_over_epochs.append(self.weights)\n",
    "            biases_over_epochs.append(self.biases)\n",
    "            if epoch == 0 or (epoch + 1) % n_epochs_displayed == 0:\n",
    "                print(f'Epoch {epoch + 1}: loss_fun={losses[-1]}')\n",
    "        return losses, weights_over_epochs, biases_over_epochs\n",
    "    \n",
    "    def fit_minibatch(self, X, Y, first_lr = 0.01, lr_decay_rate=0.01, epochs = 100, n_epochs_displayed = 100, batch_size = 32):\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        losses = []\n",
    "        weights_over_epochs = [self.weights]\n",
    "        biases_over_epochs = [self.biases]\n",
    "        for epoch in range(epochs):\n",
    "            permutation = np.random.permutation(X.shape[0])\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                D_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "                D_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "                for j in range(i, min(i + batch_size, X.shape[0])):\n",
    "                    D_weights_temp, D_biases_temp = self._backward(X[j], Y[j])\n",
    "                    for k in range(len(self.weights)):\n",
    "                        D_weights[k] += D_weights_temp[k]\n",
    "                        D_biases[k] += D_biases_temp[k]\n",
    "                learning_rate = first_lr / (1 + epoch * lr_decay_rate)\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= learning_rate * D_weights[j] / batch_size\n",
    "                    self.biases[j] -= learning_rate * D_biases[j] / batch_size\n",
    "            losses.append(self.mse(self.predict(X), Y))\n",
    "            weights_over_epochs.append(self.weights)\n",
    "            biases_over_epochs.append(self.biases)\n",
    "            if epoch == 0 or (epoch + 1) % n_epochs_displayed == 0:\n",
    "                print(f'Epoch {epoch + 1}: loss_fun={losses[-1]}')\n",
    "        return losses, weights_over_epochs, biases_over_epochs\n",
    "                \n",
    "    def set_all_weights(self, weights):\n",
    "        self.weights = weights\n",
    "\n",
    "    def set_weights_for_layer(self, layer, weights):\n",
    "        self.weights[layer] = weights\n",
    "\n",
    "    def set_weigth(self, layer, from_neuron, to_neuron, value):\n",
    "        self.weights[layer][from_neuron][to_neuron] = value\n",
    "\n",
    "    def set_all_biases(self, biases):\n",
    "        self.biases = biases\n",
    "\n",
    "    def set_biases_for_layer(self, layer, biases):\n",
    "        self.biases[layer] = biases\n",
    "\n",
    "    def set_bias(self, layer, neuron, value):\n",
    "        self.biases[layer][neuron] = value\n",
    "\n",
    "    def set_act_fun(self, act_fun):\n",
    "        act_fun_prime = None\n",
    "        if act_fun == 'sigmoid':\n",
    "            act_fun = lambda x: 1 / (1 + np.exp(-x))\n",
    "            act_fun_prime = lambda x: np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "\n",
    "        if act_fun == 'relu':\n",
    "            act_fun = lambda x: np.maximum(0, x)\n",
    "            act_fun_prime = lambda x: np.where(x > 0, 1, 0)\n",
    "\n",
    "        if act_fun == 'tanh':\n",
    "            act_fun = lambda x: np.tanh(x)\n",
    "            act_fun_prime = lambda x: 1 - np.tanh(x) ** 2\n",
    "            \n",
    "        self.act_fun = act_fun\n",
    "        self.act_fun_prime = act_fun_prime\n",
    "\n",
    "    def set_out_act_fun(self, out_act_fun_is_linear):\n",
    "        if not out_act_fun_is_linear:\n",
    "            self.out_act_fun = self.act_fun\n",
    "            self.out_act_fun_prime = self.act_fun_prime\n",
    "            return\n",
    "        self.out_act_fun = lambda x: x\n",
    "        self.out_act_fun_prime = lambda x: 1\n",
    "    \n",
    "\n",
    "    def mse(self, y, y_pred):\n",
    "        return np.mean((y - y_pred) ** 2) / 2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, min = None, max = None):\n",
    "    data = np.array(data)\n",
    "    if min is None:\n",
    "        min = np.min(data)\n",
    "\n",
    "    if max is None:\n",
    "        max = np.max(data)\n",
    "\n",
    "    return (data - min) / (max - min), min, max    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(data, min, max):\n",
    "    data = np.array(data)\n",
    "    return data * (max - min) + min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network_for_epoch(weights, biases, epoch):\n",
    "    G = nx.Graph()\n",
    "    n_layers = len(weights) + 1\n",
    "    n_neurons = [len(layer) for layer in weights] + [len(biases[-1])]\n",
    "\n",
    "    max_abs_weight = max([np.max(np.abs(layer)) for layer in weights])\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        for j in range(n_neurons[i]):\n",
    "            G.add_node(f'{i}-{j}')\n",
    "    for i in range(n_layers - 1):\n",
    "        for j in range(n_neurons[i]):\n",
    "            for k in range(n_neurons[i + 1]):\n",
    "                G.add_edge(f'{i}-{j}', f'{i + 1}-{k}', weight=weights[i][j][k])\n",
    "    \n",
    "    pos = {}\n",
    "    max_n_neurons = max(n_neurons)\n",
    "    for i in range(n_layers):\n",
    "        for j in range(n_neurons[i]):\n",
    "            pos[f'{i}-{j}'] = (i, max_n_neurons - n_neurons[i] + 2 * j)\n",
    "    \n",
    "    cmap = plt.get_cmap('RdYlGn')\n",
    "    norm = plt.Normalize(vmin=-max_abs_weight, vmax=max_abs_weight)\n",
    "    edge_colors = [cmap(norm(G[u][v]['weight'])) for u, v in G.edges()]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(f'Epoch {epoch}')\n",
    "    nx.draw(\n",
    "        G, \n",
    "        pos,\n",
    "        edge_color=edge_colors,\n",
    "        node_size=3000, \n",
    "        font_size=10, \n",
    "        width=[abs(G[u][v]['weight']) + 1 for u, v in G.edges()]\n",
    "    )\n",
    "    node_labels = {f'{i+1}-{j}': f'{biases[i][j][0]:.2f}' for i in range(n_layers - 1) for j in range(n_neurons[i + 1])}\n",
    "    nx.draw_networkx_labels(G, pos, labels=node_labels)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f'{G[u][v][\"weight\"]:.2f}' for u, v in G.edges()})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_networks_for_epochs(weights_over_epochs, biases_over_epochs, epochs):\n",
    "    for epoch in epochs:\n",
    "        draw_network_for_epoch(weights_over_epochs[epoch], biases_over_epochs[epoch], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method, first_lr, lr_decay_rate, epochs, n_epochs_displayed = 100, batch_size = 32):\n",
    "    X_train_norm, x_min, x_max = normalize(X_train)\n",
    "    Y_train_norm, y_min, y_max = normalize(Y_train)\n",
    "    X_test_norm, _, _ = normalize(X_test, x_min, x_max)\n",
    "\n",
    "    if method == 'sgd':\n",
    "        losses, weights_over_epochs, biases_over_epochs = model.fit_SGD(X_train_norm, Y_train_norm, first_lr, lr_decay_rate, epochs, n_epochs_displayed)\n",
    "    elif method == 'batch':\n",
    "        losses, weights_over_epochs, biases_over_epochs = model.fit_batch(X_train_norm, Y_train_norm, first_lr, lr_decay_rate, epochs, n_epochs_displayed)\n",
    "    elif method == 'minibatch':\n",
    "        losses, weights_over_epochs, biases_over_epochs = model.fit_minibatch(X_train_norm, Y_train_norm, first_lr, lr_decay_rate, epochs, n_epochs_displayed, batch_size)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax[0].scatter(X_train, Y_train, color='blue', label='true')\n",
    "    ax[0].scatter(X_train, denormalize(model.predict(X_train_norm), y_min, y_max), color='red', label='prediction')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    ax[0].set_title('Denormalised train data')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(range(epochs), losses)\n",
    "    ax[1].set_xlabel('epoch')\n",
    "    ax[1].set_title(f'Denormalised train set MSE={model.mse(Y_train, denormalize(model.predict(X_train_norm), y_min, y_max)):.2f}')\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax[0].scatter(X_test, Y_test, color='blue', label='true')\n",
    "    ax[0].scatter(X_test, denormalize(model.predict(X_test_norm), y_min, y_max), color='red', label='prediction')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    ax[0].set_title('Denormalised test data')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].text(0.5, 0.5, f'Denormalised test set MSE={model.mse(Y_test, denormalize(model.predict(X_test_norm), y_min, y_max)):.2f}', fontsize=15, ha='center')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return losses, weights_over_epochs, biases_over_epochs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Square-simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/regression/square-simple-training.csv', index_col=0)['x']\n",
    "Y_train = pd.read_csv('data/regression/square-simple-training.csv', index_col=0)['y']\n",
    "X_test = pd.read_csv('data/regression/square-simple-test.csv', index_col=0)['x']\n",
    "Y_test = pd.read_csv('data/regression/square-simple-test.csv', index_col=0)['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 5, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "losses, weights_over_epochs, biases_over_epochs = train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'sgd', first_lr = 0.5, lr_decay_rate = 0, epochs = 1000, n_epochs_displayed = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "draw_networks_for_epochs(weights_over_epochs, biases_over_epochs, [0, 1, 10, 100, 500, 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 5, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'minibatch', first_lr = 0.5, lr_decay_rate = 0, epochs = 1000, n_epochs_displayed = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 5, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'batch', first_lr = 0.5, lr_decay_rate = 0, epochs = 1000, n_epochs_displayed = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowując, z tymi samymi hiperparametrami, szybkość zbieżności to $SGD < MiniBatch(batch\\_size=10\\%) < Batch$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/regression/steps-small-training.csv')['x']\n",
    "Y_train = pd.read_csv('data/regression/steps-small-training.csv')['y']\n",
    "X_test = pd.read_csv('data/regression/steps-small-test.csv')['x']\n",
    "Y_test = pd.read_csv('data/regression/steps-small-test.csv')['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 5, 5, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "losses, weights_over_epochs, biases_over_epochs = train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'sgd', first_lr = 0.9, lr_decay_rate = 1e-5, epochs = 200000, n_epochs_displayed = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "draw_networks_for_epochs(weights_over_epochs, biases_over_epochs, [0, 1, 1000, 10000, 100000, 150000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/regression/multimodal-large-training.csv')['x']\n",
    "Y_train = pd.read_csv('data/regression/multimodal-large-training.csv')['y']\n",
    "X_test = pd.read_csv('data/regression/multimodal-large-test.csv')['x']\n",
    "Y_test = pd.read_csv('data/regression/multimodal-large-test.csv')['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 10, 10, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'sgd', first_lr = 0.1, lr_decay_rate = 1e-3, epochs = 1000, n_epochs_displayed = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 10, 10, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'minibatch', first_lr = 0.3, lr_decay_rate = 0, epochs = 200, n_epochs_displayed=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model = MLP([1, 10, 10, 1], 'sigmoid', out_act_fun_is_linear = True)\n",
    "train_and_draw_plots(model, X_train, Y_train, X_test, Y_test, method = 'batch', first_lr = 0.1, lr_decay_rate = 1e-2, epochs = 200, n_epochs_displayed=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
